options {
    DEBUG_TOKEN_MANAGER = false;
    DEBUG_PARSER = false;
    UNICODE_INPUT = true;
    STATIC = false;
    TOKEN_EXTENDS = "PositionToken";
    COMMON_TOKEN_ACTION = true;
    USER_CHAR_STREAM = true;
}
PARSER_BEGIN(PythonParser)
package io.joern.pythonparser;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Stack;
import io.joern.pythonparser.ast.Module;
import io.joern.pythonparser.ast.*;
public class PythonParser {
  static class BoxedObject<T> {
    T object;
    BoxedObject(T object) {
      this.object = object;
    }
  }
  TokenAttributeProvider attributes(Token startToken, Token endToken) {
    return new TokenAttributeProvider(startToken, endToken);
  }
  NodeAttributeProvider attributes(iattributes attributeAstNode, Token endToken) {
    return new NodeAttributeProvider(attributeAstNode, endToken);
  }

  private ArrayList<ErrorStatement> errors = new ArrayList<ErrorStatement>();
  ArrayList<ErrorStatement> getErrors() {
    return errors;
  }

  ErrorStatement recoverAndCreateErrorStmt(Token lastCorrectToken, Exception exception) {
    try {
      getNextToken();
      while (token.kind != SEMICOLON && token.kind != NEWLINE && token.kind != EOF) {
        getNextToken();
      }
    } catch (Exception e) {
      // We are already in error handling/recovery mode and try to advance the token stream
      // to a point where we have hope to parse something meaningful again. If we get an
      // exception during this advancing we end up here.
      // We just stop advancing, store the previous error which brought us here in the first
      // place and hope the parse can recover from the current state.
    }

    Token errorStartToken = lastCorrectToken.next;
    ErrorStatement errorStmt = new ErrorStatement(exception, attributes(errorStartToken, token));
    errors.add(errorStmt);
    return errorStmt;
  }

  // Since this grammar is handling python3 and python2 code, we need to deal with
  // abiguities between those two python versions.
  // One such ambiguity is caused by the print statements (not expressions) like:
  //   print (x), y
  // In python3 this is a Tuple(elts = [Call(func = print, args = [x]), y])
  // whereas in python this is a Call(func = print, args = [Tuple(elts = [x]), y]).
  // Our grammar parses this as a python3 style tuple and this method rewrites the
  // tuple to the python2 style call.
  // The reasoning for this is that a statement with a top level tuple used in no
  // expression is superfluous and thus a rare unexpected case. One could argue
  // that this case is also expected to be rare in python2 so only time will tell
  // whether this was the right choice.
  istmt printStatmentToPython2StyleRewrite(istmt stmt) {
    if (stmt instanceof Expr) {
      Expr expr = (Expr) stmt;
      if (expr.value() instanceof Tuple) {
        Tuple tuple = (Tuple)expr.value();
        if (tuple.elts().nonEmpty() && tuple.elts().head() instanceof Call) {
          Call call = (Call) tuple.elts().head();
          if (call.func() instanceof Name) {
            Name name = (Name) call.func();
            if (name.id().equals("print") && call.keywords().isEmpty()) {
              ArrayList<iexpr> combinedArgs = new ArrayList<iexpr>();
              int argCount = call.args().size();
              for (int i = 0; i < argCount; i++) {
                combinedArgs.add(call.args().apply(i));
              }
              int elementCount = tuple.elts().size();
              for (int i = 1; i < elementCount; i++) {
                combinedArgs.add(tuple.elts().apply(i));
              }
              return stmt = new Expr(
                new Call(call.func(), combinedArgs, new ArrayList<Keyword>(),
                 call.attributeProvider()));
            }
          }
        }
      }
    }
    return stmt;
  }
}
PARSER_END(PythonParser)

TOKEN_MGR_DECLS:
{
  // All kinds of parentheses are tracked here: ( { [
  Stack<Integer> parenthesesStack = new Stack<Integer>();
  int currentIndent = 0;
  int dedentsToEmit;
  Stack<Integer> indentStack = new Stack<Integer>();
  {
    pushParenScope();
    indentStack.push(0);
  }

  void pushParenScope() {
    parenthesesStack.push(0);
  }

  void popParenScope() {
    parenthesesStack.pop();
  }

  void countOpenParen() {
     Integer top = parenthesesStack.pop();
     parenthesesStack.push(top + 1);
  }

  void countCloseParen() {
     Integer top = parenthesesStack.pop();
     parenthesesStack.push(top - 1);
  }

  int openParenCounter() {
    return parenthesesStack.peek();
  }

  // matchedToken must have the form: <prefix><oneOrThreeQuotes>
  // The matched tokens image this cut to not contain <oneOrThreeQuotes>
  // and the input stream is backed up by the length(<oneOrThreeQuotes>)
  String adjustTokenAndBackupInput(Token matchedToken, int prefixLen) {
    int quoteLen = matchedToken.image.length() - prefixLen;
    String result = matchedToken.image.substring(0, matchedToken.image.length() - quoteLen);
    input_stream.backup(quoteLen);
    return result;
  }

  // Cut token image by quote length since we do not want the close quote in the content.
  String cutContentTokenImage(Token matchedToken, int quoteLen) {
    String result = matchedToken.image.substring(0, matchedToken.image.length() - quoteLen);
    return result;
  }

  // Cut content token image by length of endToken1 or endToken2 since we do not them in the content.
  // In our case this is either a close quote or "{".
  // We also backup the input by this length to generate an extra token for close quote or "{"
  String cutContentTokenImageAndBackupInput(Token matchedToken, String endToken1, String endToken2) {

    int length;
    if (matchedToken.image.endsWith(endToken1)) {
        length = endToken1.length();
    } else if (matchedToken.image.endsWith(endToken2)) {
        length = endToken2.length();
    } else {
        throw new RuntimeException("Unexpected end of matchedToken " + matchedToken.image);
    }
    String result = matchedToken.image.substring(0, matchedToken.image.length() - length);
    input_stream.backup(length);
    return result;
  }

  // Stores the format string lexing state we were in before switching to the DEFAULT state
  // in order to parse a replacement field. Naturally needs to be a stack since replacement
  // fields can be nested.
  // Note that during format string lexing of strings containing multiple replacement fields,
  // we switch back and forth multiple times between the lexer DEFAULT state and the stacks
  // top state.
  Stack<Integer> formatStringLexStateStack = new Stack<Integer>();

  // Number of opened curly brackets while parsing a format string in FORMAT_SPEC_LEX.
  int formatSpecOpenCurly = 0;

  void CommonTokenAction(Token token) {
    CharStreamImpl inputStreamImpl = (CharStreamImpl)input_stream;
    token.startPos = inputStreamImpl.getBeginPos();
    token.endPos = token.startPos + token.image.length();
  }
}

TOKEN: {
  <IF: "if">
| <ELSE: "else">
| <ELIF: "elif">
| <OR: "or">
| <AND: "and">
| <NOT: "not">
| <DEF: "def">
| <ASYNC: "async">
| <LAMBDA: "lambda">
| <FOR: "for">
| <WITH: "with">
| <RETURN: "return">
| <TRY: "try">
| <EXCEPT: "except">
| <FINALLY: "finally">
| <CLASS: "class">
| <WHILE: "while">
| <IMPORT: "import">
| <FROM: "from">
| <AS: "as">
| <RAISE: "raise">
| <PASS: "pass">
| <DEL: "del">
| <YIELD: "yield">
| <ASSERT: "assert">
| <BREAK: "break">
| <CONTINUE: "continue">
| <GLOBAL: "global">
| <NONLOCAL: "nonlocal">
| <AWAIT: "await">
| <NONE: "None">
| <TRUE: "True">
| <FALSE: "False">
| <ARROW: "->">
| <ELLIPSIS: "...">
| <COLON: ":"> {
  // Only on top level of the replacement field lexing we can
  // switch into the format spec lexing. At top level
  // openParenCounter() is 1 because of the opening curly bracket.
  if (!formatStringLexStateStack.isEmpty() && openParenCounter() == 1) {
    // We reached a ":" of a format spec of a replacement field of a format string.
    SwitchTo(FORMAT_SPEC_LEX);
  }
}
| <SEMICOLON: ";">
| <COMMA: ",">
| <ASSIGN: "=">
| <COLON_ASSIGN: ":=">
| <PLUS_ASSIGN: "+=">
| <MINUS_ASSIGN: "-=">
| <STAR_ASSIGN: "*=">
| <AT_ASSIGN: "@=">
| <DIV_ASSIGN: "/=">
| <MOD_ASSIGN: "%=">
| <BIT_AND_ASSIGN: "&=">
| <BIT_OR_ASSIGN: "|=">
| <BIT_XOR_ASSIGN: "^=">
| <LSHIFT_ASSIGN: "<<=">
| <RSHIFT_ASSIGN: ">>=">
| <POW_ASSIGN: "**=">
| <FLOOR_DIV_ASSIGN: "//=">
| <EQ: "==">
| <NEQ: "!=">
| <LT: "<">
| <LTE: "<=">
| <GT: ">">
| <GTE: ">=">
| <IS: "is">
| <IN: "in">
| <PLUS: "+">
| <MINUS: "-">
| <AT: "@">
| <DIV: "/">
| <FLOOR_DIV: "//">
| <MOD: "%">
| <INVERT: "~">
| <LSHIFT: "<<">
| <RSHIFT: ">>">
| <BIT_OR: "|">
| <BIT_XOR: "^">
| <BIT_AND: "&">
| <PAREN_OPEN: "("> { countOpenParen(); }
| <PAREN_CLOSE: ")"> { countCloseParen(); }
| <SQUARE_OPEN: "["> { countOpenParen(); }
| <SQUARE_CLOSE: "]"> { countCloseParen(); }
| <CURLY_OPEN: "{"> { countOpenParen(); }
| <CURLY_CLOSE: "}"> {
  countCloseParen();
  if (!formatStringLexStateStack.isEmpty() && openParenCounter() == 0) {
    popParenScope();
    SwitchTo(formatStringLexStateStack.peek());
  }
}
| <DOT: ".">
| <STAR: "*">
| <DOUBLE_STAR: "**">
| <STR_CONVERSION: "!s">
| <REPR_CONVERSION: "!r">
| <ASCII_CONVERSION: "!a">
}

// Number tokens:
TOKEN: {
  <DEC_INTEGER: <NON_ZERO_DIGIT> (("_")? <DIGIT>)* | "0" (("_")? "0")*>
| <BIN_INTEGER: "0" ("b" | "B") (("_")? <BIN_DIGIT>)+>
| <OCT_INTEGER:
  (
    "0"  ("o" | "O") (("_")? <OCT_DIGIT>)+
  | // Just a leading 0 without a following o or 0 is python2 style.
    // This conflicts with the new python3 decimal integer style of writing
    // zero as an arbitrary number of 0.
    // This the DEC_INTEGER rule is defined first such a literal is
    // tokenized as DEC_INTEGER. So we prioritize python3 here.
    // Since the resulting integer value is in both cases zero the slight
    // loss precession for python2 seems exceptable.
  "0" (<OCT_DIGIT>)+
  )
  >
| <HEX_INTEGER: "0" ("x" | "X") (("_")? <HEX_DIGIT>)+>
| <#DIGIT: ["0" - "9"] >
| <#NON_ZERO_DIGIT: ["1" - "9"] >
| <#BIN_DIGIT: "0" | "1" >
| <#OCT_DIGIT: ["0" - "7"] >
| <#HEX_DIGIT: ["0" - "9"] | ["a" - "f"] | ["A" - "F"] >
| <FLOAT:
  (
    (<DIGIT_PART> "." (<DIGIT_PART>)? (<EXPONENT>)?)
  | ("." <DIGIT_PART> (<EXPONENT>)?)
  | (<DIGIT_PART> <EXPONENT>)
  )
  >
| <#EXPONENT: ("e" | "E") ("+" | "-")? <DIGIT_PART>>
| <#DIGIT_PART: <DIGIT> (("_")? <DIGIT>)*>
| <IMAGINARY: (<FLOAT> | <DIGIT_PART>) ("j" | "J")>
}

TOKEN: {
  <NAME: <LETTER> (<LETTER> | <DIGIT>)*>
| <LETTER: ["a" - "z", "A" - "Z", "_", "À" - "Ö", "Ø" - "ö", "ø" - "ÿ"] >
}

SKIP: {
  <SPACE: " " | "\t">
  // Here and for all other places where we match newline,
  // it is not necessary to separately match the combined
  // versions like "\n\r". This is ok because interpreting
  // the second character as a separate newline is always
  // fine because bland lines are ignored.
| <SKIPPED_NEWLINE: "\n" | "\r"> {
    if (openParenCounter() == 0) {
      SwitchTo(NEWLINE_EMIT);
    }
  }
| <LINE_JOIN: "\\" ("\n" | "\r" | "\r\n")>
}

SPECIAL_TOKEN: {
  <COMMENT: "#" (~["\n", "\r"])*>
}


<INDENT_CHECK> SPECIAL_TOKEN: {
  <INDENT_CHECK_COMMENT: "#" (~["\n", "\r"])*>
}

<INDENT_CHECK> SKIP: {
  <INDENT_CHECK_SPACE: " "> { currentIndent += 1; }
| <INDENT_CHECK_TAB: "\t">  { currentIndent = currentIndent / 8 + 8; }
| <INDENT_CHECK_NEWLINE: "\n" | "\r"> { currentIndent = 0; }
| <INDENT_CHECK_END: ~[]> {
    // Rewind input stream by the one consumed character because we dont
    // really wont to skip it. We just used it as the end marker for the
    // indentation check. The documentation says input_stream is read only
    // so we are a little bit of the beaten path here but so far it works.
    input_stream.backup(1);

    int lastIndent = indentStack.peek();
    if (currentIndent > lastIndent) {
      indentStack.push(currentIndent);
      SwitchTo(INDENT_EMIT);
    } else if (currentIndent < lastIndent) {
      assert(dedentsToEmit == 0);

      while (currentIndent < lastIndent) {
        dedentsToEmit += 1;
        indentStack.pop();
        lastIndent = indentStack.peek();
      }

      if (currentIndent == lastIndent) {
        SwitchTo(DEDENT_EMIT);
      } else {
        SwitchTo(MISSDENT_EMIT);
      }
    } else {
      SwitchTo(DEFAULT);
    }
    currentIndent = 0;
  }
}

<MISSDENT_EMIT> TOKEN: {
  // Defining this as ""|"" causes javaCC to produce better readable debug output
  // in the form a proper tokenImage string <MISSDENT> instead of "". This has no
  // impact on the generated matching code in the state.
  <MISSINDENT: "" | ""> {
      SwitchTo(DEFAULT);
  }
}

<INDENT_EMIT> TOKEN: {
  // Defining this as ""|"" causes javaCC to produce better readable debug output
  // in the form a proper tokenImage string <INDENT> instead of "". This has no
  // impact on the generated matching code in the state.
  <INDENT: "" | ""> {
      SwitchTo(DEFAULT);
  }
}

<DEDENT_EMIT> TOKEN: {
  // Defining this as ""|"" causes javaCC to produce better readable debug output
  // in the form a proper tokenImage string <DEDENT> instead of "". This has no
  // impact on the generated matching code in the state.
  <DEDENT: "" | ""> {
      dedentsToEmit -= 1;
      if (dedentsToEmit == 0) {
        SwitchTo(DEFAULT);
      }
      // This disables the build in infinite loop detection.
      // We take care of not looping forever by decrementing
      // dedentsToEmit.
      jjbeenHere[DEDENT_EMIT] = false;
  }
}

<NEWLINE_EMIT> TOKEN: {
  // Defining this as ""|"" causes javaCC to produce better readable debug output
  // in the form a proper tokenImage string <MISSDENT> instead of "". This has no
  // impact on the generated matching code in the state.
  <NEWLINE: "" | ""> {
    SwitchTo(INDENT_CHECK);
  }
}

///////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////
// String lexer rules:
///////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////
TOKEN: {
  <STRING_PREFIX:
  ("r" | "R" | "b" | "B" | "u" | "U")
  ("\"" | "'" | "\"\"\"" | "'''")> {
    matchedToken.image = adjustTokenAndBackupInput(matchedToken, 1);
  }
| <STRING_PREFIX2:
  ("rb" | "rB" | "Rb" | "RB" | "br" | "bR" | "Br" | "BR" | "ur" | "uR" | "Ur" | "UR")
  ("\"" | "'" | "\"\"\"" | "'''")> {
    matchedToken.image = adjustTokenAndBackupInput(matchedToken, 2);
    matchedToken.kind = STRING_PREFIX;
  }
| <FORMAT_STRING_PREFIX:
  ("f" | "F")
  ("\"" | "'" | "\"\"\"" | "'''")> {
    matchedToken.image = adjustTokenAndBackupInput(matchedToken, 1);
  } : FORMAT_STRING_LEX
| <FORMAT_STRING_PREFIX2:
  ("rf" | "rF" | "Rf" | "RF" | "fr" | "fR" | "Fr" | "FR")
  ("\"" | "'" | "\"\"\"" | "'''")> {
    matchedToken.image = adjustTokenAndBackupInput(matchedToken, 2);
    matchedToken.kind = FORMAT_STRING_PREFIX;
  } : FORMAT_STRING_LEX
}

///////////////////////////////////////////////////////////////////////////////
// Normal string lexer rules:
///////////////////////////////////////////////////////////////////////////////

// The lexer state NEVER is never reached. We use it only to define common lexer token kinds
// to which the different string lexer map to provide a uniform interface to the parsing stage.
<NEVER> TOKEN: {
  <STRING_QUOTE_OPEN: "STRING_QUOTE_OPEN">
| <STRING_CONTENT: "STRING_CONTENT">
}

// NSDQ stands for: normal single double quote
// NSSQ stands for: normal single single quote
// NTDQ stands for: normal triple double quote
// NTSQ stands for: normal single double quote
TOKEN: {
  <NSDQ_QUOTE_OPEN: "\"" > { matchedToken.kind = STRING_QUOTE_OPEN; }: NSDQ_LEX
| <NSSQ_QUOTE_OPEN: "'"> { matchedToken.kind = STRING_QUOTE_OPEN; }: NSSQ_LEX
| <NTDQ_QUOTE_OPEN: "\"\"\""> { matchedToken.kind = STRING_QUOTE_OPEN; }: NTDQ_LEX
| <NTSQ_QUOTE_OPEN: "'''"> { matchedToken.kind = STRING_QUOTE_OPEN; }: NTSQ_LEX
}

<NSDQ_LEX> TOKEN: {
  <NSDQ_CONTENT: "\""> {
    matchedToken.image = cutContentTokenImage(matchedToken, 1);
    matchedToken.kind = STRING_CONTENT;
  }: DEFAULT
}
<NSDQ_LEX> MORE: {
  <NSDQ_ESCAPED_ESCAPE: "\\\\">
| <NSDQ_ESCAPED_QUOTE: "\\\"">
| <NSDQ_ANY: ~[]>
}

<NSSQ_LEX> TOKEN: {
  <NSSQ_CONTENT: "'"> {
    matchedToken.image = cutContentTokenImage(matchedToken, 1);
    matchedToken.kind = STRING_CONTENT;
  }: DEFAULT
}
<NSSQ_LEX> MORE: {
  <NSSQ_ESCAPED_ESCAPE: "\\\\">
| <NSSQ_ESCAPED_QUOTE: "\\'">
| <NSSQ_ANY: ~[]>
}

<NTDQ_LEX> TOKEN: {
  <NTDQ_CONTENT: "\"\"\""> {
    matchedToken.image = cutContentTokenImage(matchedToken, 3);
    matchedToken.kind = STRING_CONTENT;
  }: DEFAULT
}
<NTDQ_LEX> MORE: {
  <NTDQ_ESCAPED_ESCAPE: "\\\\">
| <NTDQ_ESCAPED_QUOTE: "\\\"">
| <NTDQ_ANY: ~[]>
}

<NTSQ_LEX> TOKEN: {
  <NTSQ_CONTENT: "'''"> {
    matchedToken.image = cutContentTokenImage(matchedToken, 3);
    matchedToken.kind = STRING_CONTENT;
  }: DEFAULT
}
<NTSQ_LEX> MORE: {
  <NTSQ_ESCAPED_ESCAPE: "\\\\">
| <NTSQ_ESCAPED_QUOTE: "\\'">
| <NTSQ_ANY: ~[]>
}


///////////////////////////////////////////////////////////////////////////////
// Format string lexer rules:
///////////////////////////////////////////////////////////////////////////////
// TODO currently we parse format specs as one single string and do not break it down in its elements.
<FORMAT_SPEC_LEX> MORE: {
  <FORMAT_SPEC_CURLY_OPEN: "{"> {
    formatSpecOpenCurly += 1;
  }
| <FORMAT_SPEC_CURLY_CLOSE: "}"> {
    formatSpecOpenCurly -= 1;
    if (formatSpecOpenCurly < 0) {
      formatSpecOpenCurly = 0;
      SwitchTo(FORMAT_SPEC_LEX_EMIT);
    }
  }
| <FORMAT_SPEC_ANY: ~[]>
}
<FORMAT_SPEC_LEX_EMIT> TOKEN: {
  <FORMAT_SPEC: ""> {
    // We get here with an already matched closing curly bracket for the entire replacement
    // field. Thus we need to cut the token image by one to remove the closing curly bracket
    // and also we backup the input stream by one in order to generate a separate token for
    // it in DEFAULT state to indicate the replacement field end.
    matchedToken.image = matchedToken.image.substring(0, matchedToken.image.length() - 1);
    input_stream.backup(1);
  }: DEFAULT
}

// The lexer state NEVER is never reached. We use it only to define common lexer token kinds
// to which the different string lexer map to provide a uniform interface to the parsing stage.
<NEVER> TOKEN: {
  <FORMAT_STRING_QUOTE_OPEN: "FORMAT_STRING_QUOTE_OPEN">
| <FORMAT_STRING_CONTENT: "FORMAT_STRING_CONTENT">
| <FORMAT_STRING_QUOTE_CLOSE: "FORMAT_STRING_QUOTE_CLOSE">
| <FORMAT_STRING_CURLY_OPEN: "FORMAT_STRING_CURLY_OPEN">
}

// FSDQ stands for: formatted single double quote
// FSSQ stands for: formatted single single quote
// FTDQ stands for: formatted triple double quote
// FTSQ stands for: formatted triple single quote
<FORMAT_STRING_LEX> TOKEN: {
  <FSDQ_QUOTE_OPEN: "\""> { formatStringLexStateStack.push(FSDQ_LEX); matchedToken.kind = FORMAT_STRING_QUOTE_OPEN; }: FSDQ_LEX
| <FSSQ_QUOTE_OPEN: "'"> { formatStringLexStateStack.push(FSSQ_LEX); matchedToken.kind = FORMAT_STRING_QUOTE_OPEN; }: FSSQ_LEX
| <FTDQ_QUOTE_OPEN: "\"\"\""> { formatStringLexStateStack.push(FTDQ_LEX); matchedToken.kind = FORMAT_STRING_QUOTE_OPEN; }: FTDQ_LEX
| <FTSQ_QUOTE_OPEN: "'''"> { formatStringLexStateStack.push(FTSQ_LEX); matchedToken.kind = FORMAT_STRING_QUOTE_OPEN; }: FTSQ_LEX
}

<FSDQ_LEX> TOKEN: {
  <FSDQ_CONTENT: "{" | "\"" > {
    matchedToken.image = cutContentTokenImageAndBackupInput(matchedToken, "{", "\"");
    matchedToken.kind = FORMAT_STRING_CONTENT;
  }: FSDQ_LEX_EMIT_END
}
<FSDQ_LEX> MORE: {
  <FSDQ_ESCAPED_ESCAPE: "\\\\">
| <FSDQ_ESCAPED_QUOTE: "\\\"">
| <FSDQ_ESCAPED_CURLY: "{{">
| <FSDQ_ANY: ~[]>
}
<FSDQ_LEX_EMIT_END> TOKEN: {
  <FSDQ_CURLY_OPEN: "{"> {
   matchedToken.kind = FORMAT_STRING_CURLY_OPEN;
   pushParenScope();
   countOpenParen();
  }: DEFAULT
| <FSDQ_END: "\""> { formatStringLexStateStack.pop(); matchedToken.kind = FORMAT_STRING_QUOTE_CLOSE; }: DEFAULT
}

<FSSQ_LEX> TOKEN: {
  <FSSQ_CONTENT: "{" | "'" > {
    matchedToken.image = cutContentTokenImageAndBackupInput(matchedToken, "{", "'");
    matchedToken.kind = FORMAT_STRING_CONTENT;
  }: FSSQ_LEX_EMIT_END
}
<FSSQ_LEX> MORE: {
  <FSSQ_ESCAPED_ESCAPE: "\\\\">
| <FSSQ_ESCAPED_QUOTE: "\\'">
| <FSSQ_ESCAPED_CURLY: "{{">
| <FSSQ_ANY: ~[]>
}
<FSSQ_LEX_EMIT_END> TOKEN: {
  <FSSQ_CURLY_OPEN: "{"> {
   matchedToken.kind = FORMAT_STRING_CURLY_OPEN;
   pushParenScope();
   countOpenParen();
  }: DEFAULT
| <FSSQ_END: "'"> { formatStringLexStateStack.pop(); matchedToken.kind = FORMAT_STRING_QUOTE_CLOSE; }: DEFAULT
}

<FTDQ_LEX> TOKEN: {
  <FTDQ_CONTENT: "{" | "\"\"\"" > {
    matchedToken.image = cutContentTokenImageAndBackupInput(matchedToken, "{", "\"\"\"");
    matchedToken.kind = FORMAT_STRING_CONTENT;
  }: FTDQ_LEX_EMIT_END
}
<FTDQ_LEX> MORE: {
  <FTDQ_ESCAPED_ESCAPE: "\\\\">
| <FTDQ_ESCAPED_QUOTE: "\\\"">
| <FTDQ_ESCAPED_CURLY: "{{">
| <FTDQ_ANY: ~[]>
}
<FTDQ_LEX_EMIT_END> TOKEN: {
  <FTDQ_CURLY_OPEN: "{"> {
   matchedToken.kind = FORMAT_STRING_CURLY_OPEN;
   pushParenScope();
   countOpenParen();
  }: DEFAULT
| <FTDQ_END: "\"\"\""> { formatStringLexStateStack.pop(); matchedToken.kind = FORMAT_STRING_QUOTE_CLOSE; }: DEFAULT
}

<FTSQ_LEX> TOKEN: {
  <FTSQ_CONTENT: "{" | "'''" > {
    matchedToken.image = cutContentTokenImageAndBackupInput(matchedToken, "{", "'''");
    matchedToken.kind = FORMAT_STRING_CONTENT;
  }: FTSQ_LEX_EMIT_END
}
<FTSQ_LEX> MORE: {
  <FTSQ_ESCAPED_ESCAPE: "\\\\">
| <FTSQ_ESCAPED_QUOTE: "\\'">
| <FTSQ_ESCAPED_CURLY: "{{">
| <FTSQ_ANY: ~[]>
}
<FTSQ_LEX_EMIT_END> TOKEN: {
  <FTSQ_CURLY_OPEN: "{"> {
   matchedToken.kind = FORMAT_STRING_CURLY_OPEN;
   pushParenScope();
   countOpenParen();
  }: DEFAULT
| <FTSQ_END: "'''"> { formatStringLexStateStack.pop(); matchedToken.kind = FORMAT_STRING_QUOTE_CLOSE; }: DEFAULT
}

///////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////
// Parser rules start:
///////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////

Module module(): {
  ArrayList<istmt> allStmts = new ArrayList<istmt>();
  ArrayList<istmt> stmts;
} {
  try {
    (
      stmts = statementsAndDedentOrEof() { allStmts.addAll(stmts); }
    | <EOF>
    )
    { return new Module(allStmts, new ArrayList<TypeIgnore>()); }
  } catch (ParseException exception) {
    ErrorStatement errorStmt = recoverAndCreateErrorStmt(token, exception);
    allStmts.add(errorStmt);
    if (token.kind != EOF) {
      ArrayList<istmt> postRecoverStmts = statementsAndDedentOrEof();
      allStmts.addAll(postRecoverStmts);
    }
    return new Module(allStmts, new ArrayList<TypeIgnore>());
  }
}

// This is the "statements" rule from the CPython 3.9 grammar with a modification:
// Also consume the <DEDENT> or <EOF> which must follow.
// We do this for easy of error handling.
ArrayList<istmt> statementsAndDedentOrEof(): {
  ArrayList<istmt> allStmts = new ArrayList<istmt>();
  ArrayList<istmt> simpleStmts;
  istmt stmt;
} {
  try {
    (
      stmt = compoundStatement() { allStmts.add(stmt); }
    | simpleStmts = simpleStatement() { allStmts.addAll(simpleStmts); }
    )+
    (<DEDENT> | <EOF>)
    { return allStmts; }
  } catch (ParseException exception) {
    ErrorStatement errorStmt = recoverAndCreateErrorStmt(token, exception);
    allStmts.add(errorStmt);
    if (token.kind != EOF) {
      ArrayList<istmt> postRecoverStmts = statementsAndDedentOrEof();
      allStmts.addAll(postRecoverStmts);
    }
    return allStmts;
  }
}

// Error handling strategy:
// In case of a parse exception we search in the token stream for the next
// <SEMICOLON>, <NEWLINE> or <EOF> and than return the so far parsed statements.
// To not return "accidental" statements, a small statement is considered pending
// until a following <SEMICOLON>, <NEWLINE> or <EOF> was parsed.
// An "accidental" statement would be the "x" in "x y = 1". At first we successfully
// parse a <NAME> and after that we are missing a ";" or got one "y" too much. But
// only in the first case returning an "x" statement would be ok and since we dont
// know that we rather not return anything that was not terminated by the above
// special characters.
ArrayList<istmt> simpleStatement(): {
  istmt pendingStmt = null;
  ArrayList<istmt> stmts = new ArrayList<istmt>();
} {
  try {
    (pendingStmt = smallStatement())
    (LOOKAHEAD(2)
      <SEMICOLON> { if (pendingStmt != null) stmts.add(pendingStmt); pendingStmt = null; }
      pendingStmt = smallStatement()
    )*
    (<SEMICOLON> { if (pendingStmt != null) stmts.add(pendingStmt); pendingStmt = null; })?
    (<NEWLINE>|<EOF>)
    {
      if (pendingStmt != null) {
        stmts.add(pendingStmt);
      }
      return stmts;
    }
  } catch (ParseException exception) {
    Token lastCorrectToken = token;
    if (pendingStmt != null && pendingStmt instanceof Expr) {
      Expr expr = (Expr)pendingStmt;
      if (expr.value() instanceof Name) {
        Name name = (Name)expr.value();
        try {
          if (name.id().equals("print")) {
            // We got a parsing failure after a "print" Name expression.
            // Try to interpret as python2 print statement.
            istmt printStmt = printStatementPython2(name);
            stmts.add(printStmt);
            return stmts;
          } else if (name.id().equals("exec")) {
            // We got a parsing failure after a "exec" Name expression.
            // Try to interpret as python2 exec statement.
            istmt execStmt = execStatementPython2(name);
            stmts.add(execStmt);
            return stmts;
          }
        } catch (ParseException printException) {
          // If something goes wrong trying to parse as python2
          // statement, we can rely on the error recovery already for
          // the initial parse error.
        }
      }
    }
    ErrorStatement errorStmt = recoverAndCreateErrorStmt(lastCorrectToken, exception);
    stmts.add(errorStmt);
    // We do not need to recursively invoke simpleStatement() here because the surrounding
    // rule does that already.
    return stmts;
  }
}

// printName is the already parsed "print" Name expression.
// Since this rule is only expected to be called in error
// recovery, it needs to consume trailing semicolons and
// newline to finish the simpleStatement context and
// allow normal parsing to continue.
istmt printStatementPython2(Name printName): {
  iexpr expr;
  ArrayList<iexpr> arguments = new ArrayList<iexpr>();
} {
  expr = expression() { arguments.add(expr); }
  (LOOKAHEAD(2)
    <COMMA>
    expr = expression() { arguments.add(expr); }
  )*
  (<COMMA>)*
  (
    (<SEMICOLON> (<NEWLINE> | <EOF>)?)
  | <NEWLINE>
  | <EOF>
  )
  {
    return new Expr(
      new Call(printName, arguments, new ArrayList<Keyword>(), attributes(printName, token)));
  }
}

// execName is the already parsed "exec" Name expression.
// Since this rule is only expected to be called in error
// recovery, it needs to consume trailing semicolons and
// newline to finish the simpleStatement context and
// allow normal parsing to continue.
istmt execStatementPython2(Name execName): {
  iexpr codeExpr;
  iexpr globalsExpr = null;
  iexpr localsExpr = null;
} {
  codeExpr = bitwiseOr()
  (
    <IN>
    globalsExpr = expression()
    (
      <COMMA>
      localsExpr = expression()
    )?
  )?
  (
    (<SEMICOLON> (<NEWLINE> | <EOF>)?)
  | <NEWLINE>
  | <EOF>
  )
  {
    ArrayList<iexpr> arguments = new ArrayList<iexpr>();
    arguments.add(codeExpr);
    if (globalsExpr != null) {
      arguments.add(globalsExpr);
    }
    if (localsExpr != null) {
      arguments.add(localsExpr);
    }
    return new Expr(
      new Call(execName, arguments, new ArrayList<Keyword>(), attributes(execName, token)));
  }
}


istmt smallStatement(): {
  istmt stmt;
} {
  (
  stmt = assignmentOrExpr() { stmt = printStatmentToPython2StyleRewrite(stmt); }
| stmt = returnStatement()
| stmt = importStatement()
| stmt = raiseStatement()
| stmt = passStatement()
| stmt = delStatement()
| stmt = yieldStatement()
| stmt = assertStatement()
| stmt = breakStatement()
| stmt = continueStatement()
| stmt = globalStatement()
| stmt = nonlocalStatement()
  )
  {
    return stmt;
  }
}

// We are little bit less restrictive than the python 3.9 grammar because
// we allow logical expressions in star expressions to be returned.
// E.g. "return * x and y" the python 3.9 grammar would require parenthesis:
// "return *(x and y)".
Return returnStatement(): {
  iexpr expression = null;
  Token startToken;
} {
  <RETURN> { startToken = token; } (expression = starExpressions())?
  {
    return new Return(expression, attributes(startToken, token));
  }
}

istmt importStatement(): {
  istmt stmt;
} {
  (
    stmt = importName()
  | stmt = importFrom()
  )
  { return stmt; }
}

Import importName(): {
  ArrayList<Alias> names;
  Token startToken;
} {
  <IMPORT> { startToken = token; } names = dottedAsNames()
  { return new Import(names, attributes(startToken, token)); }
}

ArrayList<Alias> dottedAsNames(): {
  Alias name;
  ArrayList<Alias> names = new ArrayList<Alias>();
} {
  name = dottedAsName() { names.add(name); }
  (<COMMA> name = dottedAsName() { names.add(name); })*
  { return names; }
}

Alias dottedAsName(): {
  String dottedName;
  String asName = null;
} {
  dottedName = dottedName() (<AS> <NAME>{ asName = token.image; })?
  { return new Alias(dottedName, asName); }
}

String dottedName(): {
  String dottedName;
} {
  <NAME> { dottedName = token.image; }
  (<DOT> <NAME> { dottedName = dottedName + "." + token.image; })*
  { return dottedName; }
}

ImportFrom importFrom(): {
  int level = 0;
  String module = null;
  ArrayList<Alias> names;
  Token startToken;
} {
  <FROM> { startToken = token; }
  (<DOT> { level += 1; } | <ELLIPSIS> { level += 3; })*
  (module = dottedName())?
  <IMPORT>
  names = importFromTargets()
  {
    if (level != 0 || module != null) {
      return new ImportFrom(module, names, level, attributes(startToken, token));
    } else {
      throw new ParseException("TODO");
    }
  }
}

ArrayList<Alias> importFromTargets(): {
  Alias name;
  ArrayList<Alias> names;
} {
  (
  <STAR> {
    names = new ArrayList<Alias>();
    names.add(new Alias(token.image, (String)null));
  }
| <PAREN_OPEN> names = importFromAsNames() <PAREN_CLOSE>
| names = importFromAsNames()
  )
  { return names; }
}

ArrayList<Alias> importFromAsNames(): {
  Alias name;
  ArrayList<Alias> names = new ArrayList<Alias>();
} {
  name = importFromAsName() { names.add(name); }
  (LOOKAHEAD(2)
    <COMMA> name = importFromAsName() { names.add(name); }
  )*
  (<COMMA>)?
  { return names; }
}

Alias importFromAsName(): {
  String name;
  String asName = null;
} {
  <NAME> { name = token.image; } (<AS> <NAME> { asName = token.image; })?
  { return new Alias(name, asName); }
}

istmt raiseStatement(): {
  Token startToken;
  iexpr exceptionExpr = null;
  iexpr causeExpr = null;
  iexpr instExpr = null;
  iexpr tracebackExpr = null;
} {
  <RAISE> { startToken = token; }
  (
    exceptionExpr = expression()
    (
      (<FROM> causeExpr = expression())
    | (
        <COMMA> instExpr = expression()
        (
          <COMMA> tracebackExpr = expression()
        )?
      )
    )?
  )?
  {
    if (instExpr != null) {
      return new RaiseP2(exceptionExpr, instExpr, tracebackExpr, attributes(startToken, token));
    } else {
      return new Raise(exceptionExpr, causeExpr, attributes(startToken, token));
    }
  }
}

Pass passStatement(): {
} {
  <PASS> { return new Pass(attributes(token, token)); }
}

// This is not as restrictive as the corresponding CPython 3.9 rule
// because we except a primary as target which includes e.g. number literals
// which would be invalid Python code.
Delete delStatement(): {
  Token startToken;
  iexpr target;
  ArrayList<iexpr> targets = new ArrayList<iexpr>();
} {
  <DEL> { startToken = token; }
  target = primary() { targets.add(target); }
  (LOOKAHEAD(2)
    <COMMA>
    target = primary() { targets.add(target); }
  )*
  (<COMMA>)?
  { return new Delete(targets, attributes(startToken, token)); }
}

Expr yieldStatement(): {
  iexpr yieldExpr;
} {
  yieldExpr = yieldExpression()
  { return new Expr(yieldExpr); }
}

Assert assertStatement(): {
  Token startToken;
  iexpr testExpr;
  iexpr msgExpr = null;
} {
  <ASSERT> { startToken = token; }
  testExpr = expression()
  (<COMMA> msgExpr = expression())?
  { return new Assert(testExpr, msgExpr, attributes(startToken, token)); }
}

Break breakStatement(): {
} {
  <BREAK> { return new Break(attributes(token, token)); }
}

Continue continueStatement(): {
} {
  <CONTINUE> { return new Continue(attributes(token, token)); }
}

Global globalStatement(): {
  Token startToken;
  ArrayList<String> names = new ArrayList<String>();
} {
  <GLOBAL> { startToken = token; }
  <NAME> { names.add(token.image); }
  (<COMMA> <NAME> { names.add(token.image); })*
  { return new Global(names, attributes(startToken, token)); }
}

Nonlocal nonlocalStatement(): {
  Token startToken;
  ArrayList<String> names = new ArrayList<String>();
} {
  <NONLOCAL> { startToken = token; }
  <NAME> { names.add(token.image); }
  (<COMMA> <NAME> { names.add(token.image); })*
  { return new Nonlocal(names, attributes(startToken, token)); }
}

istmt compoundStatement(): {
  istmt stmt;
} {
  (
    stmt = decoratedStatement()
  | stmt = asyncStatement()
  | stmt = functionDef(new ArrayList<iexpr>(), false, null)
  | stmt = ifStatement()
  | stmt = classDef(new ArrayList<iexpr>())
  | stmt = forStatement(false, null)
  | stmt = withStatement(false, null)
  | stmt = tryStatement()
  | stmt = whileStatement()
  )
  { return stmt; }
}

istmt decoratedStatement(): {
  ArrayList<iexpr> decorators;
  Token asyncToken;
  istmt stmt;
} {
  decorators = decorators()
  (
    stmt = functionDef(decorators, false, null)
  | (<ASYNC> { asyncToken = token; } stmt = functionDef(decorators, true, asyncToken))
  | stmt = classDef(decorators)
  )
  { return stmt; }
}

istmt asyncStatement(): {
  Token asyncToken;
  istmt stmt;
} {
  <ASYNC> { asyncToken = token; }
  (
    stmt = functionDef(new ArrayList<iexpr>(), true, asyncToken)
  | stmt = forStatement(true, asyncToken)
  | stmt = withStatement(true, asyncToken)
  )
  { return stmt; }
}

istmt functionDef(ArrayList<iexpr> decorators, boolean isAsync, Token asyncToken): {
  Token startToken = asyncToken;
  String name;
  Arguments parameters;
  iexpr returnExpr = null;
  ArrayList<istmt> blockStmts;
} {
  <DEF> { if (!isAsync) {startToken = token;} }
  <NAME> { name = token.image; }
  <PAREN_OPEN>
  parameters = parameters()
  <PAREN_CLOSE>
  (<ARROW> returnExpr = expression())?
  <COLON>
  blockStmts = block()
  {
    if (isAsync) {
      return new AsyncFunctionDef(name, parameters, blockStmts, decorators,
        returnExpr, null, attributes(startToken, token));
    } else {
      return new FunctionDef(name, parameters, blockStmts, decorators,
        returnExpr, null, attributes(startToken, token));
    }
  }
}

// Sister function of lambdaParameters.
// Only difference that type annotations and type comment are not allowed in this
// version. Changes made here should also be done in the sister function.
// This rule matches always because its contend is purely optional.
//
// This is a fully factored out version of the CPython 3.9 parameters parser rule
// minus the support for type comments which are currently swallowed by the lexer.
// Dont be confused by the inconsistent use of argument and parameter identifiers.
// Arg, Arguments, Arg and Argument class names are part of the user facing API
// with which we mimic the CPython AST API and thus their names are what they are.
// They should rather be named iparam, iparameters etc..
Arguments parameters(): {
  ArrayList<Arg> posOnlyArgs = new ArrayList<Arg>();
  ArrayList<Arg> args = new ArrayList<Arg>();
  // Contains the defaults for posOnlyArgs and args.
  ArrayList<iexpr> defaults = new ArrayList<iexpr>();
  BoxedObject<Arg> varArg = new BoxedObject<Arg>(null);
  ArrayList<Arg> kwOnlyArgs = new ArrayList<Arg>();
  // Contains the defaults for kwOnlyArgs. If such an
  // argument has no default, null is added instead.
  ArrayList<iexpr> kwDefaults = new ArrayList<iexpr>();
  BoxedObject<Arg> kwArg = new BoxedObject<Arg>(null);

  boolean defaultRequired = false;
  ArrayList<Arg> tmpArgs = new ArrayList<Arg>();
} {
  (
    (
      defaultRequired = positionalParameters(defaultRequired, args, defaults)
      (
        <COMMA>
        (
          (
            <DIV>
            { posOnlyArgs = args; args = new ArrayList<Arg>(); }
            (
              <COMMA>
              (
                (
                  positionalParameters(defaultRequired, args, defaults)
                  (
                    <COMMA>
                    (
                      starAndFollowingParameters(varArg, kwOnlyArgs, kwDefaults, kwArg)
                      | kwArg.object = doubleStarParameters()
                      | {}
                    )
                  )?
                )
              | starAndFollowingParameters(varArg, kwOnlyArgs, kwDefaults, kwArg)
              | kwArg.object = doubleStarParameters()
              | {}
              )
            )?
          )
        | starAndFollowingParameters(varArg, kwOnlyArgs, kwDefaults, kwArg)
        | kwArg.object = doubleStarParameters()
        | {}
        )
      )?
    )
  | starAndFollowingParameters(varArg, kwOnlyArgs, kwDefaults, kwArg)
  | kwArg.object = doubleStarParameters()
  | {}
  )
  {
    return new Arguments(posOnlyArgs, args, varArg.object, kwOnlyArgs,
     kwDefaults, kwArg.object, defaults);
  }
}

// Sister function of lambdaStarAndFollowingParameters.
// Only difference that type annotations and type comment are not allowed in this
// version. Changes made here should also be done in the sister function.
void starAndFollowingParameters(BoxedObject<Arg> varArg,
                                ArrayList<Arg> kwOnlyArgs,
                                ArrayList<iexpr> kwDefaults,
                                BoxedObject<Arg> kwArg): {
} {
  <STAR>
  (
    (
      varArg.object = typedFunctionParameterDef()
      (
        <COMMA>
        (
          (
            kwOnlyParameters(kwOnlyArgs, kwDefaults)
            (
              <COMMA>
              (kwArg.object = doubleStarParameters())?
            )?
          )
        | (
            kwArg.object = doubleStarParameters()
          )
        | {}
        )
      )?
    )
  | (
      <COMMA> kwOnlyParameters(kwOnlyArgs, kwDefaults)
     (
       <COMMA>
       (kwArg.object = doubleStarParameters())?
     )?
    )
  )
}

// Sister function of lambdaDoubleStarParameters.
// Only difference that type annotations and type comment are not allowed in this
// version. Changes made here should also be done in the sister function.
Arg doubleStarParameters(): {
  Arg kwArg;
} {
  <DOUBLE_STAR> kwArg = typedFunctionParameterDef()
  (<COMMA>)?
  { return kwArg; }
}

// Sister function of lambdaPositionalParameters.
// Only difference that type annotations and type comment are not allowed in this
// version. Changes made here should also be done in the sister function.
boolean positionalParameters(boolean initialDefaultRequired,
                             ArrayList<Arg> params, ArrayList<iexpr> defaults): {
  Arg param;
  iexpr defaultExpr;
  boolean defaultRequired = initialDefaultRequired;
} {
  param = typedFunctionParameterDef() { params.add(param); }
  (
    <ASSIGN> defaultExpr = expression() { defaults.add(defaultExpr); defaultRequired = true; }
  | { if (defaultRequired) { throw new ParseException("TODO"); } }
  )
  (LOOKAHEAD(2)
    <COMMA> param = typedFunctionParameterDef() { params.add(param); }
    (
      <ASSIGN> defaultExpr = expression() { defaults.add(defaultExpr); defaultRequired = true; }
    | { if (defaultRequired) { throw new ParseException("TODO"); } }
    )
  )*
  { return defaultRequired; }
}

// Sister function of lambdaKwOnlyParameters.
// Only difference that type annotations and type comment are not allowed in this
// version. Changes made here should also be done in the sister function.
void kwOnlyParameters(ArrayList<Arg> params, ArrayList<iexpr> defaults): {
  Arg param;
  iexpr defaultExpr;
} {
  param = typedFunctionParameterDef() { params.add(param); }
  (
    <ASSIGN> defaultExpr = expression() { defaults.add(defaultExpr); }
  | { defaults.add(null); }
  )
  (LOOKAHEAD(2)
    <COMMA> param = typedFunctionParameterDef() { params.add(param); }
    (
      <ASSIGN> defaultExpr = expression() { defaults.add(defaultExpr); }
    | { defaults.add(null); }
    )
  )*
}

Arg typedFunctionParameterDef(): {
  Token startToken;
  String name;
  iexpr defaultExpr = null;
} {
  <NAME> { startToken = token; name = token.image; }
  (<COLON> defaultExpr = expression())?
  { return new Arg(name, defaultExpr, null, attributes(startToken, token)); }
}

// Sister function of parameters.
// Only difference that type annotations and type comment are not allowed in this
// version. Changes made here should also be done in the sister function.
Arguments lambdaParameters(): {
  ArrayList<Arg> posOnlyArgs = new ArrayList<Arg>();
  ArrayList<Arg> args = new ArrayList<Arg>();
  // Contains the defaults for posOnlyArgs and args.
  ArrayList<iexpr> defaults = new ArrayList<iexpr>();
  BoxedObject<Arg> varArg = new BoxedObject<Arg>(null);
  ArrayList<Arg> kwOnlyArgs = new ArrayList<Arg>();
  // Contains the defaults for kwOnlyArgs. If such an
  // argument has no default, null is added instead.
  ArrayList<iexpr> kwDefaults = new ArrayList<iexpr>();
  BoxedObject<Arg> kwArg = new BoxedObject<Arg>(null);

  boolean defaultRequired = false;
  ArrayList<Arg> tmpArgs = new ArrayList<Arg>();
} {
  (
    (
      defaultRequired = lambdaPositionalParameters(defaultRequired, args, defaults)
      (
        <COMMA>
        (
          (
            <DIV>
            { posOnlyArgs = args; args = new ArrayList<Arg>(); }
            (
              <COMMA>
              (
                (
                  lambdaPositionalParameters(defaultRequired, args, defaults)
                  (
                    <COMMA>
                    (
                      lambdaStarAndFollowingParameters(varArg, kwOnlyArgs, kwDefaults, kwArg)
                      | kwArg.object = lambdaDoubleStarParameters()
                      | {}
                    )
                  )?
                )
              | lambdaStarAndFollowingParameters(varArg, kwOnlyArgs, kwDefaults, kwArg)
              | kwArg.object = lambdaDoubleStarParameters()
              | {}
              )
            )?
          )
        | lambdaStarAndFollowingParameters(varArg, kwOnlyArgs, kwDefaults, kwArg)
        | kwArg.object = lambdaDoubleStarParameters()
        | {}
        )
      )?
    )
  | lambdaStarAndFollowingParameters(varArg, kwOnlyArgs, kwDefaults, kwArg)
  | kwArg.object = lambdaDoubleStarParameters()
  | {}
  )
  {
    return new Arguments(posOnlyArgs, args, varArg.object, kwOnlyArgs,
     kwDefaults, kwArg.object, defaults);
  }
}

// Sister function of starAndFollowingParameters.
// Only difference that type annotations and type comment are not allowed in this
// version. Changes made here should also be done in the sister function.
void lambdaStarAndFollowingParameters(BoxedObject<Arg> varArg,
                                      ArrayList<Arg> kwOnlyArgs,
                                      ArrayList<iexpr> kwDefaults,
                                      BoxedObject<Arg> kwArg): {
} {
  <STAR>
  (
    (
      varArg.object = lambdaFunctionParameterDef()
      (
        <COMMA>
        (
          (
            lambdaKwOnlyParameters(kwOnlyArgs, kwDefaults)
            (
              <COMMA>
              (kwArg.object = lambdaDoubleStarParameters())?
            )?
          )
        | (
            kwArg.object = lambdaDoubleStarParameters()
          )
        | {}
        )
      )?
    )
  | (
      <COMMA> lambdaKwOnlyParameters(kwOnlyArgs, kwDefaults)
     (
       <COMMA>
       (kwArg.object = lambdaDoubleStarParameters())?
     )?
    )
  )
}

// Sister function of doubleStarParameters.
// Only difference that type annotations and type comment are not allowed in this
// version. Changes made here should also be done in the sister function.
Arg lambdaDoubleStarParameters(): {
  Arg kwArg;
} {
  <DOUBLE_STAR> kwArg = lambdaFunctionParameterDef()
  (<COMMA>)?
  { return kwArg; }
}

// Sister function of positionalParameters.
// Only difference that type annotations and type comment are not allowed in this
// version. Changes made here should also be done in the sister function.
boolean lambdaPositionalParameters(boolean initialDefaultRequired,
                                   ArrayList<Arg> params, ArrayList<iexpr> defaults): {
  Arg param;
  iexpr defaultExpr;
  boolean defaultRequired = initialDefaultRequired;
} {
  param = lambdaFunctionParameterDef() { params.add(param); }
  (
    <ASSIGN> defaultExpr = expression() { defaults.add(defaultExpr); defaultRequired = true; }
  | { if (defaultRequired) { throw new ParseException("TODO"); } }
  )
  (LOOKAHEAD(2)
    <COMMA> param = lambdaFunctionParameterDef() { params.add(param); }
    (
      <ASSIGN> defaultExpr = expression() { defaults.add(defaultExpr); defaultRequired = true; }
    | { if (defaultRequired) { throw new ParseException("TODO"); } }
    )
  )*
  { return defaultRequired; }
}

// Sister function of kwOnlyParameters.
// Only difference that type annotations and type comment are not allowed in this
// version. Changes made here should also be done in the sister function.
void lambdaKwOnlyParameters(ArrayList<Arg> params, ArrayList<iexpr> defaults): {
  Arg param;
  iexpr defaultExpr;
} {
  param = lambdaFunctionParameterDef() { params.add(param); }
  (
    <ASSIGN> defaultExpr = expression() { defaults.add(defaultExpr); }
  | { defaults.add(null); }
  )
  (LOOKAHEAD(2)
    <COMMA> param = lambdaFunctionParameterDef() { params.add(param); }
    (
      <ASSIGN> defaultExpr = expression() { defaults.add(defaultExpr); }
    | { defaults.add(null); }
    )
  )*
}

Arg lambdaFunctionParameterDef(): {
  Token startToken;
  String name;
} {
  <NAME> { startToken = token; name = token.image; }
  { return new Arg(name, null, (String)null, attributes(startToken, token)); }
}

If ifStatement(): {
  Token startToken;
  iexpr testExpr;
  ArrayList<istmt> blockStmts;
  ArrayList<istmt> elseStmts;
} {
  <IF> { startToken = token; }
  testExpr = namedExpression()
  <COLON>
  blockStmts = block()
  (elseStmts = elifBlock() | elseStmts = elseBlock() | { elseStmts = new ArrayList<istmt>(); })
  { return new If(testExpr, blockStmts, elseStmts, attributes(startToken, token)); }
}

// Returns a list with one If statement to ease usage of this rule.
ArrayList<istmt> elifBlock(): {
  Token startToken;
  iexpr testExpr;
  ArrayList<istmt> blockStmts;
  ArrayList<istmt> elseStmts;
} {
  <ELIF> { startToken = token; }
  testExpr = namedExpression()
  <COLON>
  blockStmts = block()
  (elseStmts = elifBlock() | elseStmts = elseBlock() | { elseStmts = new ArrayList<istmt>(); })
  {
    ArrayList<istmt> stmts = new ArrayList<istmt>();
    stmts.add(new If(testExpr, blockStmts, elseStmts, attributes(startToken, token)));
    return stmts;
  }
}

ArrayList<istmt> elseBlock(): {
  ArrayList<istmt> stmts;
} {
  <ELSE> <COLON> stmts = block() { return stmts; }
}

ClassDef classDef(ArrayList<iexpr> decorators): {
  Token startToken;
  String name;
  ArrayList<iexpr> bases = new ArrayList<iexpr>();
  ArrayList<Keyword> keywords = new ArrayList<Keyword>();
  ArrayList<istmt> blockStmts;
} {
  <CLASS> { startToken = token; } <NAME> { name = token.image; }
  (<PAREN_OPEN> arguments(bases, keywords) <PAREN_CLOSE>)?
  <COLON>
  blockStmts = block()
  { return new ClassDef(name, bases, keywords, blockStmts, decorators,
     attributes(startToken, token)); }
}

ArrayList<iexpr> decorators(): {
  iexpr namedExpression;
  ArrayList<iexpr> decoratorExpressions = new ArrayList<iexpr>();
} {
  (
    <AT>
    namedExpression = namedExpression() { decoratorExpressions.add(namedExpression); }
    <NEWLINE>
  )+
  { return decoratorExpressions; }
}

istmt forStatement(boolean isAsync, Token asyncToken): {
  Token startToken = asyncToken;
  iexpr target;
  iexpr iter;
  ArrayList<istmt> blockStmts;
  ArrayList<istmt> elseStmts;
} {
  <FOR> { if (!isAsync) {startToken = token;} }
  target = starTargets()
  <IN>
  iter = starExpressions()
  <COLON>
  blockStmts = block()
  (elseStmts = elseBlock() | { elseStmts = new ArrayList<istmt>(); })
  {
    if (isAsync) {
      return new AsyncFor(target, iter, blockStmts, elseStmts, null, attributes(startToken, token));
    } else {
      return new For(target, iter, blockStmts, elseStmts, null, attributes(startToken, token));
    }
  }
}

istmt withStatement(boolean isAsync, Token asyncToken): {
  Token startToken = asyncToken;
  ArrayList<Withitem> items;
  ArrayList<istmt> blockStmts;
} {
  <WITH> { if (!isAsync) {startToken = token;} }
  // The following choice starts with an ambiguity because the first Withitem could
  // be a parenthesized expression. Without LOOKAHEAD(2) JavaCC thus complains as
  // expected. With LOOKAHEAD(2) there is still an ambiguity but JavaCC for whatever
  // reason stops complaining an opportunistically takes the first choice if possible
  // which is what we want here, although i dont fully understand it.
  (LOOKAHEAD(2)
    (
      <PAREN_OPEN>
      items = withItems()
      <PAREN_CLOSE>
    )
  | (
      items = withItems()
    )
  )
  <COLON>
  blockStmts = block()
  {
    if (isAsync) {
      return new AsyncWith(items, blockStmts, null, attributes(startToken, token));
    } else {
      return new With(items, blockStmts, null, attributes(startToken, token));
    }
  }
}

ArrayList<Withitem> withItems(): {
  ArrayList<Withitem> items = new ArrayList<Withitem>();
  Withitem item;
} {
  item = withItem() { items.add(item); }
  (LOOKAHEAD(2)
    <COMMA>
    item = withItem() { items.add(item); }
  )*
  (<COMMA>)?
  { return items; }
}

Withitem withItem(): {
  iexpr contextExpr;
  iexpr optionalVars = null;
} {
  contextExpr = expression()
  (<AS> optionalVars = starTarget())?
  { return new Withitem(contextExpr, optionalVars); }
}

Try tryStatement(): {
  Token startToken;
  ArrayList<istmt> blockStmts;
  ExceptHandler exceptHandler;
  ArrayList<ExceptHandler> exceptHandlers = new ArrayList<ExceptHandler>();
  ArrayList<istmt> elseStmts;
  ArrayList<istmt> finallyStmts;
} {
  <TRY> { startToken = token; }
  <COLON>
  blockStmts = block()
  (
    finallyStmts = finallyBlock()
    { return new Try(blockStmts, exceptHandlers, new ArrayList<istmt>(), finallyStmts,
     attributes(startToken, token)); }
  | (
      (exceptHandler = exceptBlock() { exceptHandlers.add(exceptHandler); })+
      (elseStmts = elseBlock() | { elseStmts = new ArrayList<istmt>(); })
      (finallyStmts = finallyBlock() | { finallyStmts = new ArrayList<istmt>(); })
      { return new Try(blockStmts, exceptHandlers, elseStmts, finallyStmts,
       attributes(startToken, token)); }
    )
  )
}

ExceptHandler exceptBlock(): {
  Token startToken;
  iexpr typeExpr = null;
  String name = null;
  ArrayList<istmt> blockStmts;
} {
  <EXCEPT> { startToken = token; }
  (
    typeExpr = expression()
    (
      // The COMMA is only valid in python2.
      (<AS> | <COMMA>) <NAME> { name = token.image; }
    )?
  )?
  <COLON>
  blockStmts = block()
  { return new ExceptHandler(typeExpr, name, blockStmts, attributes(startToken, token)); }
}

ArrayList<istmt> finallyBlock(): {
  ArrayList<istmt> blockStmts;
} {
  <FINALLY>
  <COLON>
  blockStmts = block()
  { return blockStmts; }
}

While whileStatement(): {
  Token startToken;
  iexpr testExpr;
  ArrayList<istmt> blockStmts;
  ArrayList<istmt> elseStmts;
} {
  <WHILE> { startToken = token; }
  testExpr = namedExpression()
  <COLON>
  blockStmts = block()
  (elseStmts = elseBlock() | { elseStmts = new ArrayList<istmt>(); })
  { return new While(testExpr, blockStmts, elseStmts, attributes(startToken, token)); }
}

ArrayList<istmt> block(): {
  ArrayList<istmt> stmts;
} {
  ((
  <NEWLINE>
  <INDENT>
  stmts = statementsAndDedentOrEof()
  )
| stmts = simpleStatement()) {
    return stmts;
 }
}

istmt assignmentOrExpr(): {
  iexpr targetExpr;
  iexpr expr = null;
  iexpr valueExpr = null;
  iexpr annotationExpr = null;
  boolean isSimple = false;
  ArrayList<iexpr> targets;
  ioperator op;
} {
  targetExpr = starExpressions() { isSimple = token.kind == NAME; }
  (
    (
      <COLON> annotationExpr = expression()
      (
        <ASSIGN> (valueExpr = yieldExpression() | valueExpr = starExpressions())
      )?
      {
        return new AnnAssign(targetExpr, annotationExpr, valueExpr, isSimple,
         attributes(targetExpr, token));
      }
    )
  | (
      (
        <PLUS_ASSIGN> { op = Add$.MODULE$; }
      | <MINUS_ASSIGN> { op = Sub$.MODULE$;}
      | <STAR_ASSIGN> { op = Mult$.MODULE$;}
      | <AT_ASSIGN> { op = MatMult$.MODULE$;}
      | <DIV_ASSIGN> { op = Div$.MODULE$;}
      | <MOD_ASSIGN> { op = Mod$.MODULE$;}
      | <BIT_AND_ASSIGN> { op = BitAnd$.MODULE$;}
      | <BIT_OR_ASSIGN> { op = BitOr$.MODULE$;}
      | <BIT_XOR_ASSIGN> { op = BitXor$.MODULE$;}
      | <LSHIFT_ASSIGN> { op = LShift$.MODULE$;}
      | <RSHIFT_ASSIGN> { op = RShift$.MODULE$;}
      | <POW_ASSIGN> { op = Pow$.MODULE$;}
      | <FLOOR_DIV_ASSIGN> { op = FloorDiv$.MODULE$;}
      )
      (valueExpr = yieldExpression() | valueExpr = starExpressions())
      { return new AugAssign(targetExpr, op, valueExpr, attributes(targetExpr, token)); }
    )
  | (
      {
        targets = new ArrayList<iexpr>();
        targets.add(targetExpr);
      }
      (
        <ASSIGN>
        (expr = yieldExpression() | expr = starExpressions())
        { targets.add(expr); }
      )+
      {
        valueExpr = targets.remove(targets.size() - 1);
        return new Assign(targets, valueExpr, attributes(targetExpr, token));
      }
    )
  | { return new Expr(targetExpr); }
  )
}

// Returns the expression list elements as tuple or
// a single express if the expression list contains only
// one element and does not end with a comma.
iexpr expressionsAsTuple(): {
  iexpr firstExpression;
  iexpr expression;
  ArrayList<iexpr> expressions = new ArrayList<iexpr>();
} {
  firstExpression = expression() { expressions.add(firstExpression); }
  (LOOKAHEAD(2)
   <COMMA> expression = expression() { expressions.add(expression); }
  )*
  (<COMMA>)?
  {
    if (token.kind != COMMA && expressions.size() == 1) {
      return expressions.get(0);
    } else {
      return new Tuple(expressions, attributes(firstExpression, token));
    }
  }
}

// Returns a tuple for multiple expressions and single expression with trailing comma.
// Otherwise returns the single expression.
// Grammar: (expression | starredBitwiseOr) ("," expression | starredBitwiseOr)* [","]
iexpr starExpressions(): {
  iexpr firstExpression;
  iexpr expression;
  ArrayList<iexpr> expressions = null;
} {
  (
    firstExpression = expression()
  | firstExpression = starredBitwiseOr()
  )
  (LOOKAHEAD(2)
    <COMMA>
    {
      if (expressions == null) {
        expressions = new ArrayList<iexpr>();
        expressions.add(firstExpression);
      }
    }
    (
      expression = expression()
    | expression = starredBitwiseOr()
    ) { expressions.add(expression); }
  )*
  (<COMMA>)?
  {
    if (expressions == null && token.kind != COMMA) {
      // Single expression no trailing comma.
      return firstExpression;
    }
    if (expressions == null) {
      // Single expression, trailing comma.
      expressions = new ArrayList<iexpr>();
      expressions.add(firstExpression);
    }
    return new Tuple(expressions, attributes(firstExpression, token));
  }
}

// This method is the same as starExpressions except that instead of expression it
// expects conditionalExpression.
// Returns a tuple for multiple expressions and single expression with trailing comma.
// Otherwise returns the single expression.
// Grammar: (conditionalExpression | starredBitwiseOr) ("," conditionalExpression | starredBitwiseOr)* [","]
iexpr starConditionalExpressions(): {
  iexpr firstExpression;
  iexpr expression;
  ArrayList<iexpr> expressions = null;
} {
  (
    firstExpression = conditionalExpression()
  | firstExpression = starredBitwiseOr()
  )
  (LOOKAHEAD(2)
    <COMMA>
    {
      if (expressions == null) {
        expressions = new ArrayList<iexpr>();
        expressions.add(firstExpression);
      }
    }
    (
      expression = conditionalExpression()
    | expression = starredBitwiseOr()
    ) { expressions.add(expression); }
  )*
  (<COMMA>)?
  {
    if (expressions == null && token.kind != COMMA) {
      // Single expression no trailing comma.
      return firstExpression;
    }
    if (expressions == null) {
      // Single expression, trailing comma.
      expressions = new ArrayList<iexpr>();
      expressions.add(firstExpression);
    }
    return new Tuple(expressions, attributes(firstExpression, token));
  }
}

iexpr yieldExpression(): {
  Token startToken;
  iexpr valueExpr = null;
} {
  <YIELD> { startToken = token; }
  (
    <FROM> valueExpr = expression()
    { return new YieldFrom(valueExpr, attributes(startToken, token)); }
  | valueExpr = starExpressions()
    { return new Yield(valueExpr, attributes(startToken, token)); }
  | { return new Yield((iexpr)null, attributes(startToken, token)); }
  )
}

iexpr namedExpression(): {
  iexpr expression;
  iexpr value;
} {
  expression = expression()
  (
  <COLON_ASSIGN> value = expression()
  {
    // To only accept valid code we would need to check that expression is
    // a NAME at this point. But since we want to work on best effort basis
    // we just dont check.
    expression = new NamedExpr(expression, value, attributes(expression, token)); }
  )?
  {
    return expression;;
  }
}

iexpr expression(): {
  iexpr expression;
} {
  (
    expression = conditionalExpression()
  | expression = lambda()
  )
  {
    return expression;
  }
}

iexpr conditionalExpression(): {
  iexpr expression;
  iexpr testExpression = null;
  iexpr elseExpression = null;
} {
  expression = disjunction()
  (<IF> testExpression = disjunction() <ELSE> elseExpression = expression())?
  {
    if (testExpression != null) {
      return new IfExp(testExpression, expression, elseExpression, attributes(expression, token));
    }
    return expression;
  }
}

iexpr lambda(): {
  Token startToken;
  Arguments parameters;
  iexpr body;
} {
  <LAMBDA> { startToken = token; }
  parameters = lambdaParameters()
  <COLON> body = expression()
  { return new Lambda(parameters, body, attributes(startToken, token)); }
}

iexpr disjunction(): {
  iexpr expression;
  iexpr nextExpression;
  ArrayList<iexpr> allExpressions = null;
} {
  expression = conjunction()
  (<OR> nextExpression = conjunction() {
    if (allExpressions == null) {
      allExpressions = new ArrayList<iexpr>();
      allExpressions.add(expression);
    }
    allExpressions.add(nextExpression);
  }
  )* {
    if (allExpressions != null) {
      return new BoolOp(Or$.MODULE$, allExpressions, attributes(expression, token));
    } else {
      return expression;
    }
  }
}

iexpr conjunction(): {
  iexpr expression;
  iexpr nextExpression;
  ArrayList<iexpr> allExpressions = null;
} {
  expression = inversion()
  (<AND> nextExpression = inversion() {
    if (allExpressions == null) {
      allExpressions = new ArrayList<iexpr>();
      allExpressions.add(expression);
    }
    allExpressions.add(nextExpression);
  }
  )* {
    if (allExpressions != null) {
      return new BoolOp(And$.MODULE$, allExpressions, attributes(expression, token));
    } else {
      return expression;
    }
  }
}

iexpr inversion(): {
  iexpr expression;
  Token startToken;
} {
  (<NOT> { startToken = token; }
   expression = inversion() {
     return new UnaryOp(Not$.MODULE$, expression, attributes(startToken, token)); }
  )
| expression = comparison() { return expression; }
}

iexpr comparison(): {
  iexpr expression;
  iexpr nextExpression = null;
  icompop op;
  boolean isNot = false;
  ArrayList<icompop> operators = null;
  ArrayList<iexpr> comparators = null;
} {
  expression = bitwiseOr()
  ((
  <EQ> { op = Eq$.MODULE$; }
| <NEQ> { op = NotEq$.MODULE$; }
| <LT> { op = Lt$.MODULE$; }
| <LTE> { op = LtE$.MODULE$; }
| <GT> { op = Gt$.MODULE$; }
| <GTE> { op = GtE$.MODULE$; }
| <IS> (<NOT>{ isNot = true; })? { op = isNot ? IsNot$.MODULE$:Is$.MODULE$; }
| <IN> { op = In$.MODULE$; }
| <NOT> <IN> { op = NotIn$.MODULE$; }
  )
  nextExpression = bitwiseOr() {
    if (operators == null) {
      operators = new ArrayList<icompop>();
    }
    operators.add(op);

    if (comparators == null) {
      comparators = new ArrayList<iexpr>();
    }
    comparators.add(nextExpression);
 }
  )*
  {
    if (nextExpression != null) {
      return new Compare(expression, operators, comparators, attributes(expression, token));
    } else {
      return expression;
    }
  }
}

iexpr bitwiseOr(): {
  iexpr expression;
  iexpr nextExpression;
} {
  expression = bitwiseXor()
  (
    <BIT_OR> nextExpression = bitwiseXor()
    { expression =
        new BinOp(expression, BitOr$.MODULE$, nextExpression, attributes(expression, token)); }
  )*
  {
    return expression;
  }
}

iexpr bitwiseXor(): {
  iexpr expression;
  iexpr nextExpression;
} {
  expression = bitwiseAnd()
  (
    <BIT_XOR> nextExpression = bitwiseAnd()
    { expression =
        new BinOp(expression, BitXor$.MODULE$, nextExpression, attributes(expression, token)); }
  )*
  {
    return expression;
  }
}

iexpr bitwiseAnd(): {
  iexpr expression;
  iexpr nextExpression;
} {
  expression = shiftExpr()
  (
    <BIT_AND> nextExpression = shiftExpr()
    { expression =
        new BinOp(expression, BitAnd$.MODULE$, nextExpression, attributes(expression, token)); }
  )*
  {
    return expression;
  }
}

iexpr shiftExpr(): {
  iexpr expr;
  iexpr nextExpr;
  ioperator op;
} {
  expr = sum()
  (
    (<LSHIFT> { op = LShift$.MODULE$; } | <RSHIFT> { op = RShift$.MODULE$; })
    nextExpr = sum()
    { expr = new BinOp(expr, op, nextExpr, attributes(expr, token)); }
  )*
  { return expr; }
}

iexpr sum(): {
  iexpr expr;
  iexpr nextExpr;
  ioperator op;
} {
  expr = term()
  (
    (<PLUS> { op = Add$.MODULE$; } | <MINUS> { op = Sub$.MODULE$; })
    nextExpr = term()
    { expr = new BinOp(expr, op, nextExpr, attributes(expr, token)); }
  )*
  { return expr; }
}

iexpr term(): {
  iexpr expr;
  iexpr nextExpr;
  ioperator op;
} {
  expr = factor()
  (
    (
      <STAR> { op = Mult$.MODULE$; }
    | <DIV> { op = Div$.MODULE$; }
    | <FLOOR_DIV> { op = FloorDiv$.MODULE$; }
    | <MOD> { op = Mod$.MODULE$; }
    | <AT> { op = MatMult$.MODULE$; }
    )
    nextExpr = factor()
    { expr = new BinOp(expr, op, nextExpr, attributes(expr, token)); }
  )*
  { return expr; }
}

iexpr factor(): {
  Token startToken;
  iexpr expr;
  iunaryop op;
} {
  (
  (
    (
      <PLUS> { op = UAdd$.MODULE$; }
    | <MINUS> { op = USub$.MODULE$; }
    | <INVERT> { op = Invert$.MODULE$; }
    )
    { startToken = token; }
    expr = factor()
    { expr = new UnaryOp(op, expr, attributes(startToken, token)); }
  )
| expr = power()
  )
  { return expr; }
}

iexpr power(): {
  iexpr expr;
  iexpr exponentExpr;
} {
  expr = awaitPrimary()
  (
    <DOUBLE_STAR> exponentExpr = factor()
    { expr = new BinOp(expr, Pow$.MODULE$, exponentExpr, attributes(expr, token)); }
  )?
  { return expr; }
}

iexpr awaitPrimary(): {
  iexpr expr;
} {
  expr = primary() { return expr; }
| <AWAIT> expr = primary() { return new Await(expr); }
}

iexpr primary(): {
  iexpr expression;
  ArrayList<iexpr> posArgs;
  ArrayList<Keyword> keyArgs;
  iexpr sliceExpression;
} {
  expression = atom()
  (
    (
      <PAREN_OPEN> { posArgs = new ArrayList<iexpr>(); keyArgs = new ArrayList<Keyword>(); }
      arguments(posArgs, keyArgs)
      <PAREN_CLOSE>
      { expression = new Call(expression, posArgs, keyArgs, attributes(expression, token)); }
    )
  | (
      <SQUARE_OPEN>
      sliceExpression = slices()
      <SQUARE_CLOSE>
      { expression = new Subscript(expression, sliceExpression, attributes(expression, token)); }
    )
  | (
      <DOT> <NAME> { expression = new Attribute(expression, token.image, attributes(expression, token)); }
    )
  )*
  { return expression; }
}

// Does no sanity checks like only allowing one GeneratorExp argument or only allowing ** after
// positional arguments. For our purposes thats fine.
void arguments(ArrayList<iexpr> positionalArgs, ArrayList<Keyword> keywordArgs): {
} {
  (
    argument(positionalArgs, keywordArgs)
    (
      LOOKAHEAD(2)
      <COMMA> argument(positionalArgs, keywordArgs)
    )*
    (<COMMA>)?
  )?
}

void argument(ArrayList<iexpr> positionalArgs, ArrayList<Keyword> keywordArgs): {
  iexpr expression;
  iexpr valueExpression;
  Token startToken;
  ArrayList<Comprehension> comprehensions;
} {
  (
    expression = starredExpression() { positionalArgs.add(expression); }
  | <DOUBLE_STAR> { startToken = token; } expression = expression()
   { keywordArgs.add(new Keyword((String)null, expression, attributes(startToken, token))); }
  | expression = expression()
    ( <ASSIGN> valueExpression = expression()
      { if (expression instanceof Name) {
          String keywordName = ((Name)expression).id();
          keywordArgs.add(new Keyword(keywordName, valueExpression, attributes(expression, token)));
        } else {
          throw new ParseException("TODO");
        }
      }
    | <COLON_ASSIGN> valueExpression = expression()
      { positionalArgs.add(new NamedExpr(expression, valueExpression, attributes(expression, token))); }
    | comprehensions = forIfClauses()
      { positionalArgs.add(new GeneratorExp(expression, comprehensions, attributes(expression, token))); }
    | { positionalArgs.add(expression); }
    )
  )
}

iexpr slices(): {
  iexpr expression;
  iexpr nextExpression;
  ArrayList<iexpr> tupleExpressions = null;
} {
  expression = slice()
  (
    LOOKAHEAD(2)
    <COMMA> nextExpression = slice() {
      if (tupleExpressions == null) {
        tupleExpressions = new ArrayList<iexpr>();
        tupleExpressions.add(expression);
      }
      if (nextExpression != null) {
        tupleExpressions.add(nextExpression);
      }
    }
  )*
  (<COMMA>)?
  {
    if (tupleExpressions != null) {
      return new Tuple(tupleExpressions, attributes(expression, token));
    } else {
      return expression;
    }
  }
}

// This rule matches any input in which case null is returned.
// We do this because the slice grammar cannot by properly handled
// by a ll(k) grammar.
iexpr slice(): {
  iexpr lower = null;
  iexpr upper = null;
  iexpr step = null;
  Token startToken = null;
} {

  (lower = expression())?
  (<COLON>{ startToken = token; } (upper = expression())? (<COLON> (step = expression())?)?)?
  {
    if (startToken != null) {
      if (lower != null) {
        return new Slice(lower, upper, step, attributes(lower, token));
      } else {
        return new Slice(lower, upper, step, attributes(startToken, token));
      }
    } else {
      return lower;
    }
  }
}

iexpr starredExpression(): {
  iexpr value;
  Token startToken;
} {
  <STAR> { startToken = token; }
  value = expression()
  {
    return new Starred(value, attributes(startToken, token));
  }
}

iexpr starredBitwiseOr(): {
  iexpr value;
  Token startToken;
} {
  <STAR> { startToken = token; }
  value = bitwiseOr()
  {
    return new Starred(value, attributes(startToken, token));
  }
}

iexpr atom(): {
  iexpr expression;
} {
  <NAME> { return new Name(token.image, attributes(token, token)); }
| <TRUE> { return new Constant(new BoolConstant(true), attributes(token, token)); }
| <FALSE> { return new Constant(new BoolConstant(false), attributes(token, token)); }
| <NONE> { return new Constant(NoneConstant$.MODULE$, attributes(token, token)); }
| <ELLIPSIS> { return new Constant(EllipsisConstant$.MODULE$, attributes(token, token)); }
| expression = number() { return expression; }
| expression = strings() { return expression; }
| expression = listOrListComprehension() { return expression; }
| expression = tupleOrGeneratorExpOrGroup() { return expression; }
| expression = setOrDictOrSetCompOrDictComp() { return expression; }
}

Constant number(): {
} {
  (
    (
      (<DEC_INTEGER> | <BIN_INTEGER> | <OCT_INTEGER> | <HEX_INTEGER>)
      { return new Constant(new IntConstant(token.image), attributes(token, token)); }
    )
  | (
      <FLOAT>
      { return new Constant(new FloatConstant(token.image), attributes(token, token)); }
    )
  | (
      <IMAGINARY>
      { return new Constant(new ImaginaryConstant(token.image), attributes(token, token)); }
    )
  )
}

iexpr strings(): {
  iexpr expr;
  ArrayList<iexpr> strings = null;
} {
  expr = string()
  (
    {
      if (strings == null) {
        strings = new ArrayList<iexpr>();
        strings.add(expr);
      }
    }
    expr = string() { strings.add(expr); }
  )*
  {
    if (strings == null) {
      return expr;
    } else {
      return new StringExpList(strings);
    }
  }
}

iexpr string(): {
  Token startToken = null;
  Token formatStartToken;
  String prefix = "";
  String quote;
  String content;
  ArrayList<iexpr> values;
  FormattedValue formattedValue;
} {
  (
    (<STRING_PREFIX> { prefix = token.image; startToken = token; })?
    <STRING_QUOTE_OPEN> { quote = token.image; if (startToken == null) startToken = token; }
    <STRING_CONTENT> { content = token.image; }
    // The lexer does not emit corresponding STRING_QUOTE_CLOSE since we do not need any
    // information from it. The closing quote was lexed together with the string content
    // and than cut off so that the string content token end position currently also
    // contains the quotes.
  )
  {
    return new Constant(new StringConstant(content, quote, prefix),
    attributes(startToken, token));
  }
| (
    (<FORMAT_STRING_PREFIX> )
    { prefix = token.image; formatStartToken = token; values = new ArrayList<iexpr>(); }
    <FORMAT_STRING_QUOTE_OPEN> { quote = token.image; }
    <FORMAT_STRING_CONTENT> {
      if (!token.image.equals("")) {
        Constant constant = new Constant(new JoinedStringConstant(token.image), attributes(token, token));
        values.add(constant);
      }
    }
    (
      formattedValue = replacementField()
      { values.add(formattedValue); }
      <FORMAT_STRING_CONTENT> {
        if (!token.image.equals("")) {
          Constant constant = new Constant(new JoinedStringConstant(token.image), attributes(token, token));
          values.add(constant);
        }
      }
    )*
    <FORMAT_STRING_QUOTE_CLOSE>
  )
  {
    return new JoinedString(values, quote, prefix, attributes(formatStartToken, token));
  }
}

FormattedValue replacementField(): {
  Token startToken;
  iexpr expression;
  boolean equalSign = false;
  int conversion = -1;
  String formatSpec = null;
} {
    <FORMAT_STRING_CURLY_OPEN> { startToken = token; }
    (
      expression = starConditionalExpressions()
    | expression = yieldExpression()
    )
    (<ASSIGN> { equalSign = true; })?
    (
      <STR_CONVERSION> { conversion = 115; }
    | <REPR_CONVERSION> { conversion = 114; }
    | <ASCII_CONVERSION> { conversion = 97; }
    )?
    (<COLON> <FORMAT_SPEC> { formatSpec = token.image; })?
    <CURLY_CLOSE>
    {
      return new FormattedValue(expression, conversion, formatSpec, equalSign, attributes(startToken, token));
    }
}

// Returns a tuple for multiple targets and single target with trailing comma.
// Otherwise returns the single target expression.
iexpr starTargets(): {
  ArrayList<iexpr> targets = null;
  iexpr firstTarget;
  iexpr target;
} {
  firstTarget = starTarget()
  (LOOKAHEAD(2)
    <COMMA>
    {
      if (targets == null) {
        targets = new ArrayList<iexpr>();
        targets.add(firstTarget);
      }
    }
    target = starTarget() { targets.add(target); }
  )*
  (<COMMA>)?
  {
    if (targets == null && token.kind != COMMA) {
      // Single target no trailing comma.
      return firstTarget;
    }
    if (targets == null) {
      // Single target, trailing comma.
      targets = new ArrayList<iexpr>();
      targets.add(firstTarget);
    }
    return new Tuple(targets, attributes(firstTarget, token));
  }
}

// This is not as restrictive as the corresponding CPython 3.9 star_target rule
// because we except a primary as target which includes e.g. number literals
// which would be invalid Python code.
iexpr starTarget(): {
  boolean starred = false;
  Token startToken = null;
  iexpr targetExpr;
  iexpr baseExpr;
  iexpr sliceExpr;
} {
  (<STAR> { starred = true; startToken = token; })?
  targetExpr = primary()
  {
    if (starred) {
      return new Starred(targetExpr, attributes(startToken, token));
    } else {
      return targetExpr;
    }
  }
}

iexpr listOrListComprehension(): {
  Token startToken;
  iexpr expr = null;
  ArrayList<Comprehension> comprehensions = null;
  ArrayList<iexpr> expressions = null;
} {
  <SQUARE_OPEN> { startToken = token; }
  (
    (
      (expr = namedExpression() | expr = starredBitwiseOr())
      (
        (comprehensions = forIfClauses())
      |
        (
          {
            expressions = new ArrayList<iexpr>();
            expressions.add(expr);
          }
          (LOOKAHEAD(2)
            <COMMA>
            (expr = namedExpression() | expr = starredBitwiseOr()) { expressions.add(expr); }
          )*
          (<COMMA>)?
        )
      )
    )
  | { expressions = new ArrayList<iexpr>(); }
  )
  <SQUARE_CLOSE>
  {
    if (comprehensions == null) {
      return new List(expressions, attributes(startToken, token));
    } else {
      return new ListComp(expr, comprehensions, attributes(startToken, token));
    }
  }
}

iexpr tupleOrGeneratorExpOrGroup(): {
  Token startToken;
  iexpr yieldExpr = null;
  iexpr expr = null;
  ArrayList<Comprehension> comprehensions = null;
  ArrayList<iexpr> expressions = null;
  boolean isTuple = false;
} {
  <PAREN_OPEN> { startToken = token; }
  (
    (yieldExpr = yieldExpression())
  | (
      (expr = namedExpression() | expr = starredBitwiseOr())
      (
        (comprehensions = forIfClauses())
      |
        (
          {
            expressions = new ArrayList<iexpr>();
            expressions.add(expr);
          }
          (LOOKAHEAD(2)
            <COMMA>
            (expr = namedExpression() | expr = starredBitwiseOr())
            { expressions.add(expr); isTuple = true; }
          )*
          (<COMMA> { isTuple = true; })?
        )
      )
    )
  | { expressions = new ArrayList<iexpr>(); isTuple = true; }
  )
  <PAREN_CLOSE>
  {
    if (yieldExpr != null) {
      return yieldExpr;
    } else if (comprehensions != null) {
      return new GeneratorExp(expr, comprehensions, attributes(startToken, token));
    } else if (isTuple) {
      return new Tuple(expressions, attributes(startToken, token));
    } else {
      return expr;
    }
  }
}

iexpr setOrDictOrSetCompOrDictComp(): {

  Token startToken;
  iexpr dictKeyOrSetValueExpr = null;
  iexpr doubleStarExpr = null;
  iexpr dictValueExpr = null;
  ArrayList<iexpr> keyExpressions = new ArrayList<iexpr>();
  ArrayList<iexpr> valueExpressions = new ArrayList<iexpr>();
  ArrayList<Comprehension> comprehensions = null;
  // If isSet is false it is a dict.
  boolean isSet = true;
} {
  <CURLY_OPEN> { startToken = token; }
  (
    (
      (
        dictKeyOrSetValueExpr = expression()
      | dictKeyOrSetValueExpr = starredBitwiseOr()
      | (<DOUBLE_STAR> doubleStarExpr = expression() { isSet = false; })
      )
      (
        <COLON> dictValueExpr = expression()
        {
          if (doubleStarExpr != null) {
            throw new ParseException("TODO");
          }
          isSet = false;
        }
      )?
      (
        (comprehensions = forIfClauses())
      | (
          {
            keyExpressions = new ArrayList<iexpr>();
            valueExpressions = new ArrayList<iexpr>();
            if (dictKeyOrSetValueExpr != null) {
              keyExpressions.add(dictKeyOrSetValueExpr);
            }
            if (dictValueExpr != null) {
              valueExpressions.add(dictValueExpr);
            }
            if (doubleStarExpr != null) {
              keyExpressions.add(null);
              valueExpressions.add(doubleStarExpr);
            }
          }
          (LOOKAHEAD(2)
            <COMMA>
            (
              (
                dictKeyOrSetValueExpr = expression()
                { keyExpressions.add(dictKeyOrSetValueExpr); doubleStarExpr = null;}
              )
            | (
                dictKeyOrSetValueExpr = starredBitwiseOr()
                { keyExpressions.add(dictKeyOrSetValueExpr); doubleStarExpr = null;}
              )
            | (
                <DOUBLE_STAR> doubleStarExpr = expression()
                {
                  if (isSet) {
                    throw new ParseException("TODO");
                  }
                  keyExpressions.add(null);
                  valueExpressions.add(doubleStarExpr);
                }
              )
            )
            (
              (
                <COLON> dictValueExpr = expression()
                {
                  if (isSet) {
                    throw new ParseException("TODO");
                  }
                  valueExpressions.add(dictValueExpr);
                }
              )
            | {
                if (!isSet && doubleStarExpr == null) {
                  throw new ParseException("TODO");
                }
              }
            )
          )*
          (<COMMA>)?
        )
      )
    )
  | {}
  )
  <CURLY_CLOSE>
  {
    if (isSet) {
      if (comprehensions == null) {
        return new Set(keyExpressions, attributes(startToken, token));
      } else {
        return new SetComp(dictKeyOrSetValueExpr, comprehensions, attributes(startToken, token));
      }
    } else {
      if (comprehensions == null) {
        return new Dict(keyExpressions, valueExpressions, attributes(startToken, token));
      } else {
        if (doubleStarExpr != null) {
          throw new ParseException("TODO");
        }
        return new DictComp(dictKeyOrSetValueExpr, dictValueExpr, comprehensions,
         attributes(startToken, token));
      }
    }
  }
}

ArrayList<Comprehension> forIfClauses(): {
  ArrayList<Comprehension> comprehensions = new ArrayList<Comprehension>();
  Comprehension comprehension;
} {
  (comprehension = forIfClause() { comprehensions.add(comprehension); })+
  { return comprehensions; }
}

Comprehension forIfClause(): {
  boolean isAsync = false;
  iexpr target;
  iexpr iter;
  ArrayList<iexpr> ifs = new ArrayList<iexpr>();
  iexpr ifExpr;
} {
  (<ASYNC> { isAsync = true; })?
  <FOR>
  target = starTargets()
  <IN>
  iter = disjunction()
  (<IF> ifExpr = disjunction() { ifs.add(ifExpr); })*
  { return new Comprehension(target, iter, ifs, isAsync); }
}

